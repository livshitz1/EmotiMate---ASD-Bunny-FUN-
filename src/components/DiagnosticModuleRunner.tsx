import React, { useCallback, useEffect, useMemo, useRef, useState } from 'react';
import { VoiceRecorder } from 'capacitor-voice-recorder';
import { DiagnosticModuleId, DiagnosticResult, Language } from '../types';

interface DiagnosticModuleRunnerProps {
  language: Language;
  moduleId: DiagnosticModuleId;
  onClose: () => void;
  onBack: () => void;
  onCompleted: () => void;
  onLog?: (text: string) => void;
  onResult?: (result: DiagnosticResult) => void;
}

const STEPS_PER_MODULE = 3;
const FREQUENCY_SERIES = [125, 250, 528, 741, 1000, 2000, 4000, 8000];

const DiagnosticModuleRunner: React.FC<DiagnosticModuleRunnerProps> = ({
  language,
  moduleId,
  onClose,
  onBack,
  onCompleted,
  onLog,
  onResult
}) => {
  const [started, setStarted] = useState(false);
  const [stepIndex, setStepIndex] = useState(0);
  const [busy, setBusy] = useState(false);
  const [status, setStatus] = useState('');
  const [eventLog, setEventLog] = useState<string[]>([]);

  const [micPermission, setMicPermission] = useState<'unknown' | 'granted' | 'denied'>('unknown');
  const [ambientDb, setAmbientDb] = useState<number | null>(null);
  const [lastToneHz, setLastToneHz] = useState<number | null>(null);
  const [recordingMs, setRecordingMs] = useState<number | null>(null);
  const [behaviorAnswers, setBehaviorAnswers] = useState<{ q1?: boolean; q2?: boolean }>({});
  const [speechAnswers, setSpeechAnswers] = useState<{ heardClearly?: boolean; distracted?: boolean; wantsRepeat?: boolean }>({});
  const [liveFeedback, setLiveFeedback] = useState<{ comfortNow?: boolean; distractedNow?: boolean }>({});
  const [frequencyFeedback, setFrequencyFeedback] = useState<{ likedHz?: number; dislikedHz?: number }>({});

  const [videoPermission, setVideoPermission] = useState<'unknown' | 'granted' | 'denied'>('unknown');
  const [videoRecording, setVideoRecording] = useState(false);
  const [videoCapturedMs, setVideoCapturedMs] = useState<number | null>(null);

  const [focusLostCount, setFocusLostCount] = useState(0);
  const [hiddenCount, setHiddenCount] = useState(0);
  const [motionEvents, setMotionEvents] = useState(0);
  const [motionScoreAvg, setMotionScoreAvg] = useState<number | null>(null);

  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);

  const videoStreamRef = useRef<MediaStream | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const videoStartedAtRef = useRef<number | null>(null);

  const videoElementRef = useRef<HTMLVideoElement | null>(null);
  const analysisCanvasRef = useRef<HTMLCanvasElement | null>(null);
  const analysisIntervalRef = useRef<number | null>(null);
  const prevFrameRef = useRef<Uint8ClampedArray | null>(null);
  const motionSumRef = useRef(0);
  const motionSamplesRef = useRef(0);

  const pushLog = useCallback(
    (text: string) => {
      setEventLog((prev) => [text, ...prev].slice(0, 24));
      onLog?.(text);
    },
    [onLog]
  );

  const emitResult = useCallback(
    (overrides?: Partial<DiagnosticResult>) => {
      onResult?.({
        id: moduleId + '-' + Date.now() + '-' + Math.random().toString(36).slice(2, 7),
        moduleId,
        timestamp: new Date().toISOString(),
        language,
        stepIndex,
        completed: false,
        micPermission,
        ambientDb,
        lastToneHz,
        recordingMs,
        behaviorAnswers,
        speechAnswers,
        liveFeedback,
        distractionMetrics: {
          focusLostCount,
          hiddenCount,
          motionEvents,
          motionScoreAvg: motionScoreAvg ?? undefined
        },
        preferredFrequencyHz: frequencyFeedback.likedHz ?? null,
        aversiveFrequencyHz: frequencyFeedback.dislikedHz ?? null,
        videoCaptureEnabled: videoRecording || videoCapturedMs !== null,
        videoCapturedMs,
        status,
        log: [...eventLog].reverse(),
        ...overrides
      });
    },
    [
      onResult,
      moduleId,
      language,
      stepIndex,
      micPermission,
      ambientDb,
      lastToneHz,
      recordingMs,
      behaviorAnswers,
      speechAnswers,
      liveFeedback,
      focusLostCount,
      hiddenCount,
      motionEvents,
      motionScoreAvg,
      frequencyFeedback,
      videoRecording,
      videoCapturedMs,
      status,
      eventLog
    ]
  );

  const t = useMemo(() => {
    const he = language === Language.HEBREW;
    const en = language === Language.ENGLISH;

    const moduleTitle: Record<DiagnosticModuleId, string> = he
      ? {
          frequency: '××™×¤×•×™ ×ª×“×¨×™×',
          speech: '× ×™×ª×•×— ×“×™×‘×•×¨ ×•×§×•×œ',
          intonation: '××™× ×˜×•× ×¦×™×” ×¨×’×©×™×ª',
          responsiveness: '×ª×’×•×‘×” ×©××™×¢×ª×™×ª',
          behavior: '×¤×¨×•×¤×™×œ ×”×ª× ×”×’×•×ª×™-×—×•×©×™'
        }
      : en
      ? {
          frequency: 'Frequency Mapping',
          speech: 'Speech & Voice Analysis',
          intonation: 'Emotional Intonation',
          responsiveness: 'Auditory Responsiveness',
          behavior: 'Behavioral-Sensory Profile'
        }
      : {
          frequency: 'ĞšĞ°Ñ€Ñ‚Ğ° Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚',
          speech: 'ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµÑ‡Ğ¸ Ğ¸ Ğ³Ğ¾Ğ»Ğ¾ÑĞ°',
          intonation: 'Ğ­Ğ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ‚Ğ¾Ğ½Ğ°Ñ†Ğ¸Ñ',
          responsiveness: 'Ğ¡Ğ»ÑƒÑ…Ğ¾Ğ²Ğ°Ñ Ñ€ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ',
          behavior: 'ĞŸĞ¾Ğ²ĞµĞ´ĞµĞ½Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞµĞ½ÑĞ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ'
        };

    const moduleDescription: Record<DiagnosticModuleId, string> = he
      ? {
          frequency: '× ×‘×“×•×§ ×ª×’×•×‘×” ×œ×ª×“×¨×™× ×©×•× ×™× ×‘×¦×•×¨×” ×¢×“×™× ×” ×•×‘×˜×•×—×”.',
          speech: '× ×‘×—×Ÿ ×™×¦×™×‘×•×ª ×¤×™×¥×³, ×§×¦×‘ ×“×™×‘×•×¨ ×•×‘×”×™×¨×•×ª.',
          intonation: '× ×‘×“×•×§ ×ª×’×•×‘×” ×œ×˜×•×Ÿ ×©××—, ×¢×¦×•×‘ ×•× ×™×˜×¨×œ×™.',
          responsiveness: '× ×‘×“×•×§ ×–××Ÿ ×ª×’×•×‘×”, ×¢×§×‘×™×•×ª ×•×”×¡×—×•×ª ×“×¢×ª.',
          behavior: '×©××œ×•×Ÿ ×§×¦×¨ ×œ×”×‘× ×ª ×¨×’×™×©×•×ª ×œ×¨×¢×©, ×©×™× ×” ×•×¨×™×›×•×–.'
        }
      : en
      ? {
          frequency: 'We check responses to different tones in a gentle, safe way.',
          speech: 'We assess pitch stability, speech pace, and clarity.',
          intonation: 'We check response to happy, sad, and neutral tones.',
          responsiveness: 'We assess latency, consistency, and distractibility.',
          behavior: 'Short parent questionnaire on noise, sleep, and focus.'
        }
      : {
          frequency: 'ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ¼ÑĞ³ĞºĞ¾ Ğ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾.',
          speech: 'ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ½Ğ°, Ñ‚ĞµĞ¼Ğ¿ Ğ¸ Ñ‡ĞµÑ‚ĞºĞ¾ÑÑ‚ÑŒ Ñ€ĞµÑ‡Ğ¸.',
          intonation: 'ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ´Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¹, Ğ³Ñ€ÑƒÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¸ Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½.',
          responsiveness: 'ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºÑƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°, ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¾Ñ‚Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒ.',
          behavior: 'ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¾ ÑˆÑƒĞ¼Ğµ, ÑĞ½Ğµ Ğ¸ ĞºĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸.'
        };

    return {
      moduleTitle,
      moduleDescription,
      start: he ? '×”×ª×—×œ' : en ? 'Start' : 'Ğ¡Ñ‚Ğ°Ñ€Ñ‚',
      continue: he ? '×”××©×š' : en ? 'Continue' : 'ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ',
      complete: he ? '×¡×™×•× ××•×“×•×œ' : en ? 'Complete Module' : 'Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ',
      back: he ? '×—×–×¨×”' : en ? 'Back' : 'ĞĞ°Ğ·Ğ°Ğ´',
      yes: he ? '×›×Ÿ' : en ? 'Yes' : 'Ğ”Ğ°',
      no: he ? '×œ×' : en ? 'No' : 'ĞĞµÑ‚',
      stepText: (n: number, total: number) => (he ? `×©×œ×‘ ${n} ××ª×•×š ${total}` : en ? `Step ${n} of ${total}` : `Ğ¨Ğ°Ğ³ ${n} Ğ¸Ğ· ${total}`),
      startedLog: he ? '×”××•×“×•×œ ×”×ª×—×™×œ ×‘×¤×•×¢×œ.' : en ? 'The module started for real.' : 'ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½.',
      micDenied: he ? '× ×“×¨×© ××™×©×•×¨ ××™×§×¨×•×¤×•×Ÿ ×›×“×™ ×œ×”××©×™×š ×‘××•×“×•×œ ×”×–×”.' : en ? 'Microphone permission is required for this module.' : 'Ğ”Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ñƒ.',
      micTrySystem: he ? '×× ×¡×” ×œ×‘×§×© ×”×¨×©××” ×“×¨×š ×”××¢×¨×›×ª...' : en ? 'Requesting OS microphone permission...' : 'Ğ—Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ñƒ...',
      micAlreadyGranted: he ? '×”×¨×©××ª ××™×§×¨×•×¤×•×Ÿ ×›×‘×¨ ×××•×©×¨×ª ×‘××¢×¨×›×ª.' : en ? 'Microphone permission is already granted in system settings.' : 'Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ñƒ ÑƒĞ¶Ğµ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½ Ğ² ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ñ….',
      askToneFeedback: he ? '×‘×—×¨ ×ª×“×¨ ×©×”×™×” ×”×›×™ × ×¢×™× ×•×ª×“×¨ ×©×”×™×” ×¤×—×•×ª × ×¢×™×.' : en ? 'Please choose the most pleasant and least pleasant tone.' : 'Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑĞ°Ğ¼Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¸ Ğ½Ğ°Ğ¸Ğ¼ĞµĞ½ĞµĞµ Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½.',
      askSpeechFeedback: he ? '×¢× ×” ×¢×œ 3 ×©××œ×•×ª ×§×¦×¨×•×ª ×¢×œ ×”×”×§×œ×˜×” ×•×”×¡×—×•×ª ×”×“×¢×ª.' : en ? 'Answer 3 short questions about recording and distractions.' : 'ĞÑ‚Ğ²ĞµÑ‚ÑŒÑ‚Ğµ Ğ½Ğ° 3 ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ¸ Ğ¾Ñ‚Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸ÑÑ….',
      videoStart: he ? '×”×ª×—×œ ×•×™×“××• ××•×¤×¦×™×•× ×œ×™' : en ? 'Start optional video' : 'Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¾Ğ¿Ñ†. Ğ²Ğ¸Ğ´ĞµĞ¾',
      videoStop: he ? '×¢×¦×•×¨ ×•×™×“××•' : en ? 'Stop video' : 'ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾'
    };
  }, [language]);

  const getStepLabel = useCallback(
    (module: DiagnosticModuleId, step: number): string => {
      const he = language === Language.HEBREW;
      const en = language === Language.ENGLISH;
      const mapHe: Record<DiagnosticModuleId, string[]> = {
        frequency: ['×›×™×•×œ ×¡×‘×™×‘×” ×•×‘×“×™×§×ª ×¨×¢×© ×¨×§×¢', '×”×©××¢×ª ×ª×“×¨×™× ××“×•×¨×’×ª', '×¤×™×“×‘×§ ×¢×œ ×ª×“×¨×™× ×•×¡×™×›×•×'],
        speech: ['×‘×“×™×§×ª ×”×¨×©××ª ××™×§×¨×•×¤×•×Ÿ', '×”×§×œ×˜×ª ××©×¤×˜ ×§×¦×¨', '× ×™×ª×•×— + ×©××œ×•×Ÿ ×§×¦×¨'],
        intonation: ['×”×©××¢×ª ×˜×•×Ÿ × ×™×˜×¨×œ×™', '×”×©××¢×ª ×˜×•×Ÿ ×©××—/×¢×¦×•×‘', '×¡×™×›×•× ×ª×’×•×‘×” ×¨×’×©×™×ª'],
        responsiveness: ['×”×©××¢×ª ×¦×œ×™×œ ×ª×’×•×‘×”', '×‘×“×™×§×ª ×¨×¦×£ ×ª×’×•×‘×•×ª ×§×¦×¨', '×¡×™×›×•× ×™×¦×™×‘×•×ª ×ª×’×•×‘×”'],
        behavior: ['×©××œ×” 1: ×¨×’×™×©×•×ª ×œ×¨×¢×©', '×©××œ×” 2: ×©×™× ×” ×•×¨×™×›×•×–', '×¡×™×›×•× ×©××œ×•×Ÿ ×¨××©×•× ×™']
      };
      const mapEn: Record<DiagnosticModuleId, string[]> = {
        frequency: ['Environment calibration and noise check', 'Gradual frequency playback', 'Tone feedback and summary'],
        speech: ['Microphone permission check', 'Record a short sentence', 'Analysis + short questionnaire'],
        intonation: ['Play neutral tone', 'Play happy/sad tones', 'Emotional-response summary'],
        responsiveness: ['Play response tone', 'Short response sequence test', 'Response stability summary'],
        behavior: ['Q1: noise sensitivity', 'Q2: sleep and focus', 'Initial questionnaire summary']
      };
      const mapRu: Record<DiagnosticModuleId, string[]> = {
        frequency: ['ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ° ÑÑ€ĞµĞ´Ñ‹ Ğ¸ ÑˆÑƒĞ¼', 'ĞŸĞ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚', 'ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ğ¸ ÑĞ²Ğ¾Ğ´ĞºĞ°'],
        speech: ['ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ñƒ', 'Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ñ„Ñ€Ğ°Ğ·Ñ‹', 'ĞĞ½Ğ°Ğ»Ğ¸Ğ· + ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ğ¿Ñ€Ğ¾Ñ'],
        intonation: ['ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½', 'Ğ Ğ°Ğ´Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¹/Ğ³Ñ€ÑƒÑÑ‚Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½', 'Ğ¡Ğ²Ğ¾Ğ´ĞºĞ° ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸'],
        responsiveness: ['Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸', 'ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ñ‚ĞµÑÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸', 'Ğ¡Ğ²Ğ¾Ğ´ĞºĞ° ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸'],
        behavior: ['Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ 1: ÑˆÑƒĞ¼Ğ¾Ğ²Ğ°Ñ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ', 'Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ 2: ÑĞ¾Ğ½ Ğ¸ ĞºĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ñ', 'ĞĞ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ²Ğ¾Ğ´ĞºĞ° Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°']
      };

      const src = he ? mapHe : en ? mapEn : mapRu;
      return src[module][step] || src[module][0];
    },
    [language]
  );

  const ensureAudioContext = useCallback(async () => {
    if (!audioContextRef.current) {
      const Ctx = window.AudioContext || (window as any).webkitAudioContext;
      audioContextRef.current = new Ctx();
    }
    if (audioContextRef.current.state === 'suspended') {
      await audioContextRef.current.resume();
    }
    return audioContextRef.current;
  }, []);

  const requestMicPermission = useCallback(async (): Promise<boolean> => {
    try {
      const hasBefore = await VoiceRecorder.hasAudioRecordingPermission();
      if (hasBefore.value) {
        setMicPermission('granted');
        pushLog(t.micAlreadyGranted);
        return true;
      }
      pushLog(t.micTrySystem);
      const req = await VoiceRecorder.requestAudioRecordingPermission();
      if (!req.value) {
        setMicPermission('denied');
        return false;
      }
      setMicPermission('granted');
      return true;
    } catch {
      try {
        await navigator.mediaDevices.getUserMedia({ audio: true });
        setMicPermission('granted');
        pushLog(t.micAlreadyGranted);
        return true;
      } catch {
        setMicPermission('denied');
        return false;
      }
    }
  }, [pushLog, t.micAlreadyGranted, t.micTrySystem]);

  const requestMicStream = useCallback(async () => {
    if (mediaStreamRef.current) return mediaStreamRef.current;
    const ok = await requestMicPermission();
    if (!ok) throw new Error('MIC_PERMISSION_DENIED');
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaStreamRef.current = stream;
    return stream;
  }, [requestMicPermission]);

  const stopMic = useCallback(() => {
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((tr) => tr.stop());
      mediaStreamRef.current = null;
    }
  }, []);

  const teardownVideoCapture = useCallback(() => {
    if (analysisIntervalRef.current !== null) {
      window.clearInterval(analysisIntervalRef.current);
      analysisIntervalRef.current = null;
    }
    if (videoStreamRef.current) {
      videoStreamRef.current.getTracks().forEach((tr) => tr.stop());
      videoStreamRef.current = null;
    }
    mediaRecorderRef.current = null;
    videoElementRef.current = null;
    analysisCanvasRef.current = null;
    prevFrameRef.current = null;
  }, []);

  const requestVideoPermission = useCallback(async (): Promise<boolean> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
      setVideoPermission('granted');
      stream.getTracks().forEach((tr) => tr.stop());
      return true;
    } catch {
      setVideoPermission('denied');
      return false;
    }
  }, []);

  const startVideoCapture = useCallback(async () => {
    if (videoRecording) return;

    const ok = await requestVideoPermission();
    if (!ok) {
      pushLog(language === Language.HEBREW ? '×œ× × ×™×ª×Ÿ ×œ×”×¤×¢×™×œ ×•×™×“××•. ××¤×©×¨ ×œ×”××©×™×š ×‘×œ×™ ×•×™×“××•.' : language === Language.ENGLISH ? 'Could not start video. Continue without video.' : 'ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾. ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ğ¹Ñ‚Ğµ Ğ±ĞµĞ· Ğ²Ğ¸Ğ´ĞµĞ¾.');
      return;
    }

    if (!('MediaRecorder' in window)) {
      pushLog(language === Language.HEBREW ? 'MediaRecorder ×œ× ×–××™×Ÿ ×‘××›×©×™×¨ ×–×”.' : language === Language.ENGLISH ? 'MediaRecorder is not available on this device.' : 'MediaRecorder Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ½Ğ° ÑÑ‚Ğ¾Ğ¼ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğµ.');
      return;
    }

    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
    videoStreamRef.current = stream;

    const recorder = new MediaRecorder(stream);
    mediaRecorderRef.current = recorder;
    recorder.ondataavailable = () => undefined;
    recorder.start();

    const videoEl = document.createElement('video');
    videoEl.playsInline = true;
    videoEl.muted = true;
    videoEl.srcObject = stream;
    await videoEl.play().catch(() => undefined);
    videoElementRef.current = videoEl;

    const canvas = document.createElement('canvas');
    canvas.width = 64;
    canvas.height = 36;
    analysisCanvasRef.current = canvas;

    motionSumRef.current = 0;
    motionSamplesRef.current = 0;
    prevFrameRef.current = null;

    analysisIntervalRef.current = window.setInterval(() => {
      if (!videoElementRef.current || !analysisCanvasRef.current) return;
      const ctx = analysisCanvasRef.current.getContext('2d');
      if (!ctx) return;

      ctx.drawImage(videoElementRef.current, 0, 0, analysisCanvasRef.current.width, analysisCanvasRef.current.height);
      const frame = ctx.getImageData(0, 0, analysisCanvasRef.current.width, analysisCanvasRef.current.height).data;

      if (prevFrameRef.current) {
        let diff = 0;
        for (let i = 0; i < frame.length; i += 4) {
          const lum = (frame[i] + frame[i + 1] + frame[i + 2]) / 3;
          const prevLum = (prevFrameRef.current[i] + prevFrameRef.current[i + 1] + prevFrameRef.current[i + 2]) / 3;
          diff += Math.abs(lum - prevLum);
        }
        const motionScore = diff / (frame.length / 4);
        motionSumRef.current += motionScore;
        motionSamplesRef.current += 1;
        if (motionScore > 22) {
          setMotionEvents((prev) => prev + 1);
        }
      }
      prevFrameRef.current = new Uint8ClampedArray(frame);
    }, 350);

    videoStartedAtRef.current = Date.now();
    setVideoCapturedMs(null);
    setVideoRecording(true);
    pushLog(language === Language.HEBREW ? '×”×§×œ×˜×ª ×•×™×“××• ×”×ª×—×™×œ×” (××•×¤×¦×™×•× ×œ×™).' : language === Language.ENGLISH ? 'Optional video recording started.' : 'Ğ—Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ° Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ.');
  }, [language, pushLog, requestVideoPermission, videoRecording]);

  const stopVideoCapture = useCallback(() => {
    if (!videoRecording) return;

    try {
      mediaRecorderRef.current?.stop();
    } catch {
      // ignore
    }

    const elapsed = videoStartedAtRef.current ? Date.now() - videoStartedAtRef.current : 0;
    setVideoCapturedMs(elapsed > 0 ? elapsed : null);
    videoStartedAtRef.current = null;

    if (motionSamplesRef.current > 0) {
      setMotionScoreAvg(Math.round((motionSumRef.current / motionSamplesRef.current) * 10) / 10);
    }

    setVideoRecording(false);
    teardownVideoCapture();

    pushLog(language === Language.HEBREW ? '×•×™×“××• × ×¢×¦×¨. × ×•×ª×—×• ×ª× ×•×¢×” ×•×”×¡×—×•×ª ×“×¢×ª.' : language === Language.ENGLISH ? 'Video stopped. Motion/distraction metrics analyzed.' : 'Ğ’Ğ¸Ğ´ĞµĞ¾ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾. ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ/Ğ¾Ñ‚Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğ¹ Ñ€Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ğ½Ñ‹.');
  }, [language, pushLog, teardownVideoCapture, videoRecording]);

  useEffect(() => {
    if (!started) return;

    const onBlur = () => setFocusLostCount((prev) => prev + 1);
    const onVisibility = () => {
      if (document.visibilityState === 'hidden') {
        setHiddenCount((prev) => prev + 1);
      }
    };

    window.addEventListener('blur', onBlur);
    document.addEventListener('visibilitychange', onVisibility);

    return () => {
      window.removeEventListener('blur', onBlur);
      document.removeEventListener('visibilitychange', onVisibility);
    };
  }, [started]);

  useEffect(() => {
    return () => {
      stopMic();
      teardownVideoCapture();
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(() => undefined);
      }
      audioContextRef.current = null;
    };
  }, [stopMic, teardownVideoCapture]);

  const sleep = (ms: number) => new Promise((r) => setTimeout(r, ms));

  const measureAmbientNoise = useCallback(async (): Promise<number> => {
    const stream = await requestMicStream();
    const ctx = await ensureAudioContext();
    const source = ctx.createMediaStreamSource(stream);
    const analyser = ctx.createAnalyser();
    analyser.fftSize = 2048;
    source.connect(analyser);

    const data = new Uint8Array(analyser.frequencyBinCount);
    let accum = 0;
    let samples = 0;
    const startedAt = Date.now();

    while (Date.now() - startedAt < 2200) {
      analyser.getByteTimeDomainData(data);
      let sumSq = 0;
      for (let i = 0; i < data.length; i++) {
        const v = (data[i] - 128) / 128;
        sumSq += v * v;
      }
      const rms = Math.sqrt(sumSq / data.length);
      accum += rms;
      samples += 1;
      await sleep(110);
    }

    source.disconnect();
    analyser.disconnect();

    const avgRms = samples > 0 ? accum / samples : 0.0001;
    const pseudoDb = Math.max(20, Math.min(90, Math.round(20 * Math.log10(avgRms + 1e-4) + 85)));
    setAmbientDb(pseudoDb);
    return pseudoDb;
  }, [ensureAudioContext, requestMicStream]);

  const playTones = useCallback(async (freqs: number[], toneDurationMs = 900, gapMs = 240) => {
    const ctx = await ensureAudioContext();
    for (const f of freqs) {
      setLastToneHz(f);
      const osc = ctx.createOscillator();
      const gain = ctx.createGain();
      osc.type = 'sine';
      osc.frequency.value = f;
      gain.gain.value = 0.0001;
      osc.connect(gain);
      gain.connect(ctx.destination);
      osc.start();

      const durSec = toneDurationMs / 1000;
      gain.gain.exponentialRampToValueAtTime(0.09, ctx.currentTime + 0.08);
      gain.gain.exponentialRampToValueAtTime(0.0001, ctx.currentTime + durSec);

      await sleep(toneDurationMs);
      osc.stop();
      osc.disconnect();
      gain.disconnect();
      await sleep(gapMs);
    }
  }, [ensureAudioContext]);

  const recordShortSentence = useCallback(async (): Promise<number> => {
    const ok = await requestMicPermission();
    if (!ok) throw new Error('MIC_PERMISSION_DENIED');

    const canRecord = await VoiceRecorder.canDeviceVoiceRecord();
    if (!canRecord.value) throw new Error('VOICE_RECORDER_UNAVAILABLE');

    const startedRes = await VoiceRecorder.startRecording();
    if (!startedRes.value) throw new Error('VOICE_RECORDER_START_FAILED');

    const startAt = Date.now();
    await sleep(3200);
    const data = await VoiceRecorder.stopRecording();
    const duration = Date.now() - startAt;
    setRecordingMs(duration);

    pushLog(
      language === Language.HEBREW
        ? `×”×•×§×œ×˜ ××©×¤×˜ ×§×¦×¨ (${Math.round(duration / 1000)} ×©× ×³, ${Math.round((data.value.recordDataBase64?.length || 0) / 1024)}KB).`
        : language === Language.ENGLISH
        ? `Short sentence recorded (${Math.round(duration / 1000)}s, ${Math.round((data.value.recordDataBase64?.length || 0) / 1024)}KB).`
        : `ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ°Ñ Ñ„Ñ€Ğ°Ğ·Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ° (${Math.round(duration / 1000)}Ñ, ${Math.round((data.value.recordDataBase64?.length || 0) / 1024)}KB).`
    );
    return duration;
  }, [language, pushLog, requestMicPermission]);

  const runCurrentStep = useCallback(async () => {
    if (busy) return;

    setBusy(true);
    try {
      const stepNo = stepIndex;

      if (moduleId === 'frequency') {
        if (stepNo === 0) {
          setStatus(language === Language.HEBREW ? '××‘×¦×¢ ××“×™×“×ª ×¨×¢×© ×¨×§×¢...' : language === Language.ENGLISH ? 'Measuring ambient noise...' : 'Ğ˜Ğ·Ğ¼ĞµÑ€ÑÑ Ñ„Ğ¾Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑˆÑƒĞ¼...');
          const db = await measureAmbientNoise();
          pushLog(
            language === Language.HEBREW
              ? `× ××“×“ ×¨×¢×© ×¨×§×¢ ××©×•×¢×¨: ~${db}dB ${db > 45 ? '(××•××œ×¥ ×œ×¢×‘×•×¨ ×œ×¡×‘×™×‘×” ×©×§×˜×” ×™×•×ª×¨)' : '(×ª×§×™×Ÿ ×œ×”×ª×—×œ×”)'}`
              : language === Language.ENGLISH
              ? `Estimated ambient noise: ~${db}dB ${db > 45 ? '(consider moving to a quieter room)' : '(ok to proceed)'}`
              : `ĞÑ†ĞµĞ½ĞºĞ° Ñ„Ğ¾Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑˆÑƒĞ¼Ğ°: ~${db}dB ${db > 45 ? '(Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿ĞµÑ€ĞµĞ¹Ñ‚Ğ¸ Ğ² Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¸Ñ…ÑƒÑ ÑÑ€ĞµĞ´Ñƒ)' : '(Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ñ‚ÑŒ)'}`
          );
          await playTones([440], 260, 80);
          pushLog(language === Language.HEBREW ? '××•×ª ×¤×ª×™×—×” ×§×¦×¨ ×”×•×©××¢ ×›×“×™ ×œ×•×•×“× ×©×”××•×“×•×œ ×¤×¢×™×œ.' : language === Language.ENGLISH ? 'A short start cue was played to confirm the module is active.' : 'Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ».');
        }
        if (stepNo === 1) {
          setStatus(language === Language.HEBREW ? '××©××™×¢ ×¡×“×¨×ª ×ª×“×¨×™× ××“×•×¨×’×ª...' : language === Language.ENGLISH ? 'Playing gradual frequency sequence...' : 'Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ¶Ñƒ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹...');
          await playTones(FREQUENCY_SERIES, 850, 210);
          pushLog(language === Language.HEBREW ? '×”×•×©××¢×” ×¡×“×¨×ª ×ª×“×¨×™×: 125Hz, 250Hz, 528Hz, 741Hz, 1kHz, 2kHz, 4kHz, 8kHz.' : language === Language.ENGLISH ? 'Played tones: 125Hz, 250Hz, 528Hz, 741Hz, 1kHz, 2kHz, 4kHz, 8kHz.' : 'Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ñ‹ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹: 125Hz, 250Hz, 528Hz, 741Hz, 1kHz, 2kHz, 4kHz, 8kHz.');
        }
        if (stepNo === 2) {
          if (!frequencyFeedback.likedHz || !frequencyFeedback.dislikedHz) {
            setStatus(t.askToneFeedback);
            return;
          }
          setStatus(language === Language.HEBREW ? '××¡×›× ××•×“×•×œ...' : language === Language.ENGLISH ? 'Summarizing module...' : 'Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒÑ ÑĞ²Ğ¾Ğ´ĞºÑƒ...');
          await sleep(450);
          pushLog(
            language === Language.HEBREW
              ? `×¡×™×›×•× × ×©××¨: × ×¢×™×=${frequencyFeedback.likedHz}Hz, ×¤×—×•×ª × ×¢×™×=${frequencyFeedback.dislikedHz}Hz.`
              : language === Language.ENGLISH
              ? `Summary saved: pleasant=${frequencyFeedback.likedHz}Hz, less pleasant=${frequencyFeedback.dislikedHz}Hz.`
              : `Ğ¡Ğ²Ğ¾Ğ´ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°: Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½Ğ¾=${frequencyFeedback.likedHz}Hz, Ğ¼ĞµĞ½ĞµĞµ Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½Ğ¾=${frequencyFeedback.dislikedHz}Hz.`
          );
        }
      }

      if (moduleId === 'speech') {
        if (stepNo === 0) {
          setStatus(language === Language.HEBREW ? '×‘×•×“×§ ×”×¨×©××ª ××™×§×¨×•×¤×•×Ÿ...' : language === Language.ENGLISH ? 'Checking microphone permission...' : 'ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑÑ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ñƒ...');
          const ok = await requestMicPermission();
          if (!ok) throw new Error('MIC_PERMISSION_DENIED');
          pushLog(language === Language.HEBREW ? '×”×¨×©××ª ××™×§×¨×•×¤×•×Ÿ ××•×©×¨×”.' : language === Language.ENGLISH ? 'Microphone permission granted.' : 'Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ñƒ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½.');
        }
        if (stepNo === 1) {
          setStatus(language === Language.HEBREW ? '××§×œ×™×˜ ××©×¤×˜ ×§×¦×¨ (3 ×©× ×™×•×ª)...' : language === Language.ENGLISH ? 'Recording a short sentence (3s)...' : 'Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºÑƒÑ Ñ„Ñ€Ğ°Ğ·Ñƒ (3Ñ)...');
          await recordShortSentence();
        }
        if (stepNo === 2) {
          if (typeof speechAnswers.heardClearly !== 'boolean' || typeof speechAnswers.distracted !== 'boolean' || typeof speechAnswers.wantsRepeat !== 'boolean') {
            setStatus(t.askSpeechFeedback);
            return;
          }
          setStatus(language === Language.HEBREW ? '××¨×™×¥ × ×™×ª×•×— ×‘×¡×™×¡×™...' : language === Language.ENGLISH ? 'Running basic analysis...' : 'Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·...');
          await sleep(700);
          pushLog(language === Language.HEBREW ? '× ×™×ª×•×— ×‘×¡×™×¡×™ ×”×•×©×œ×: ×§×¦×‘/×‘×”×™×¨×•×ª/×™×¦×™×‘×•×ª ×¤×™×¥×³ + ×©××œ×•×Ÿ ×”×¡×—×•×ª × ×©××¨×•.' : language === Language.ENGLISH ? 'Basic analysis done: pace/clarity/pitch-stability + distraction questionnaire saved.' : 'Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½: Ñ‚ĞµĞ¼Ğ¿/Ñ‡ĞµÑ‚ĞºĞ¾ÑÑ‚ÑŒ/ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ + Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¾Ñ‚Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğ¹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹.');
        }
      }

      if (moduleId === 'intonation') {
        if (stepNo === 0) {
          setStatus(language === Language.HEBREW ? '××©××™×¢ ×˜×•×Ÿ × ×™×˜×¨×œ×™...' : language === Language.ENGLISH ? 'Playing neutral tone...' : 'ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½...');
          await playTones([440], 1200, 120);
          pushLog(language === Language.HEBREW ? '×˜×•×Ÿ × ×™×˜×¨×œ×™ ×”×•×©××¢ ×•× ×¨×©××” ×ª×’×•×‘×”.' : language === Language.ENGLISH ? 'Neutral tone played and response logged.' : 'ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½, Ñ€ĞµĞ°ĞºÑ†Ğ¸Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°.');
        }
        if (stepNo === 1) {
          setStatus(language === Language.HEBREW ? '××©××™×¢ ×˜×•×Ÿ ×©××— ×•××– ×¢×¦×•×‘...' : language === Language.ENGLISH ? 'Playing happy then sad tone...' : 'Ğ Ğ°Ğ´Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¸ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½...');
          await playTones([880, 330], 1100, 180);
          pushLog(language === Language.HEBREW ? '×¨×¦×£ ××™× ×˜×•× ×¦×™×” ×”×•×©×œ×.' : language === Language.ENGLISH ? 'Intonation sequence completed.' : 'ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ½Ñ‚Ğ¾Ğ½Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°.');
        }
        if (stepNo === 2) {
          await sleep(420);
          pushLog(language === Language.HEBREW ? '×¡×™×›×•× ××™× ×˜×•× ×¦×™×” ×¨××©×•× ×™ × ×©××¨.' : language === Language.ENGLISH ? 'Initial intonation summary saved.' : 'Ğ¡Ğ²Ğ¾Ğ´ĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ½Ñ‚Ğ¾Ğ½Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°.');
        }
      }

      if (moduleId === 'responsiveness') {
        if (stepNo === 0) {
          setStatus(language === Language.HEBREW ? '××©××™×¢ ××•×ª ×ª×’×•×‘×” ×§×¦×¨...' : language === Language.ENGLISH ? 'Playing short response cue...' : 'ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸...');
          await playTones([600], 900, 180);
          pushLog(language === Language.HEBREW ? '××•×ª ×ª×’×•×‘×” ×”×•×©××¢.' : language === Language.ENGLISH ? 'Response cue played.' : 'Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½.');
        }
        if (stepNo === 1) {
          setStatus(language === Language.HEBREW ? '××©××™×¢ ×¨×¦×£ ×§×¦×¨ ×œ××“×™×“×ª ×¢×§×‘×™×•×ª...' : language === Language.ENGLISH ? 'Playing short sequence to estimate consistency...' : 'ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ°Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸...');
          await playTones([500, 700, 500, 700], 650, 150);
          pushLog(language === Language.HEBREW ? '×¨×¦×£ ×ª×’×•×‘×•×ª ×”×•×©×œ× ×•× ×©××¨.' : language === Language.ENGLISH ? 'Response sequence completed and logged.' : 'ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¹ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°.');
        }
        if (stepNo === 2) {
          await sleep(420);
          pushLog(language === Language.HEBREW ? '×¡×™×›×•× ×ª×’×•×‘×” ×©××™×¢×ª×™×ª ×¨××©×•× ×™ × ×©××¨.' : language === Language.ENGLISH ? 'Initial auditory responsiveness summary saved.' : 'Ğ¡Ğ²Ğ¾Ğ´ĞºĞ° Ğ¿Ğ¾ ÑĞ»ÑƒÑ…Ğ¾Ğ²Ğ¾Ğ¹ Ñ€ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°.');
        }
      }

      if (moduleId === 'behavior') {
        if (stepNo === 0) {
          if (typeof behaviorAnswers.q1 !== 'boolean') {
            setStatus(language === Language.HEBREW ? '×‘×—×¨ ×ª×©×•×‘×” ×œ×©××œ×” 1 ×›×“×™ ×œ×”××©×™×š.' : language === Language.ENGLISH ? 'Choose an answer for Q1 to continue.' : 'Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ 1.');
            return;
          }
          pushLog(language === Language.HEBREW ? `×©××œ×” 1 × ×©××¨×”: ${behaviorAnswers.q1 ? '×›×Ÿ' : '×œ×'}.` : language === Language.ENGLISH ? `Q1 saved: ${behaviorAnswers.q1 ? 'yes' : 'no'}.` : `Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ 1: ${behaviorAnswers.q1 ? 'Ğ´Ğ°' : 'Ğ½ĞµÑ‚'}.`);
        }
        if (stepNo === 1) {
          if (typeof behaviorAnswers.q2 !== 'boolean') {
            setStatus(language === Language.HEBREW ? '×‘×—×¨ ×ª×©×•×‘×” ×œ×©××œ×” 2 ×›×“×™ ×œ×”××©×™×š.' : language === Language.ENGLISH ? 'Choose an answer for Q2 to continue.' : 'Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ 2.');
            return;
          }
          pushLog(language === Language.HEBREW ? `×©××œ×” 2 × ×©××¨×”: ${behaviorAnswers.q2 ? '×›×Ÿ' : '×œ×'}.` : language === Language.ENGLISH ? `Q2 saved: ${behaviorAnswers.q2 ? 'yes' : 'no'}.` : `Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ 2: ${behaviorAnswers.q2 ? 'Ğ´Ğ°' : 'Ğ½ĞµÑ‚'}.`);
        }
        if (stepNo === 2) {
          await sleep(350);
          pushLog(language === Language.HEBREW ? '×¡×™×›×•× ×©××œ×•×Ÿ ×¨××©×•× ×™ × ×©××¨.' : language === Language.ENGLISH ? 'Initial questionnaire summary saved.' : 'ĞŸĞµÑ€Ğ²Ğ¸Ñ‡Ğ½Ğ°Ñ ÑĞ²Ğ¾Ğ´ĞºĞ° Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°.');
        }
      }

      const isLastStep = stepNo >= STEPS_PER_MODULE - 1;
      emitResult({ completed: isLastStep });
      if (!isLastStep) {
        setStepIndex((p) => p + 1);
      } else {
        setStatus(language === Language.HEBREW ? '×”××•×“×•×œ ×”×•×©×œ×.' : language === Language.ENGLISH ? 'Module completed.' : 'ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½.');
        onCompleted();
      }
    } catch (err) {
      console.error('Diagnostic step failed', err);
      const msg = String((err as any)?.message || '');
      if (msg.includes('MIC_PERMISSION_DENIED')) {
        setStatus(t.micDenied);
        pushLog(t.micDenied);
      } else {
        const fallback =
          language === Language.HEBREW
            ? '××™×¨×¢×” ×©×’×™××” ×‘×”×¨×¦×ª ×”×©×œ×‘. ××¤×©×¨ ×œ× ×¡×•×ª ×©×•×‘.'
            : language === Language.ENGLISH
            ? 'Step execution failed. You can try again.'
            : 'ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ ÑˆĞ°Ğ³Ğ°. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ÑĞ½Ğ¾Ğ²Ğ°.';
        setStatus(fallback);
        pushLog(fallback);
      }
      emitResult({ completed: false });
    } finally {
      setBusy(false);
    }
  }, [
    busy,
    stepIndex,
    moduleId,
    language,
    behaviorAnswers,
    speechAnswers,
    liveFeedback,
    frequencyFeedback,
    measureAmbientNoise,
    playTones,
    recordShortSentence,
    requestMicPermission,
    emitResult,
    onCompleted,
    pushLog,
    t.askSpeechFeedback,
    t.askToneFeedback,
    t.micDenied
  ]);

  const stepLabel = getStepLabel(moduleId, stepIndex);
  const progress = Math.round(((stepIndex + 1) / STEPS_PER_MODULE) * 100);
  const isLastStep = stepIndex >= STEPS_PER_MODULE - 1;

  return (
    <div className="fixed inset-0 z-[1301] bg-black/65 backdrop-blur-sm flex items-center justify-center p-4">
      <div className="w-full max-w-md rounded-3xl bg-white p-5 shadow-2xl border border-emerald-100 max-h-[90vh] overflow-y-auto">
        <div className="flex items-center justify-between mb-2">
          <h3 className="text-lg font-black text-emerald-700">ğŸ©º {t.moduleTitle[moduleId]}</h3>
          <button onClick={onClose} className="text-gray-400 hover:text-gray-700 text-2xl leading-none">Ã—</button>
        </div>

        <p className="text-sm text-gray-700 mb-2">{t.moduleDescription[moduleId]}</p>

        <div className="rounded-2xl bg-emerald-50 text-emerald-800 font-semibold p-3 mb-3 text-sm">{stepLabel}</div>

        <div className="text-xs font-bold text-emerald-700 mb-2">{t.stepText(stepIndex + 1, STEPS_PER_MODULE)}</div>
        <div className="h-2 rounded-full bg-emerald-100 overflow-hidden mb-3">
          <div className="h-full bg-emerald-500 transition-all" style={{ width: `${progress}%` }} />
        </div>

        <div className="rounded-xl bg-white border border-emerald-100 p-3 text-sm text-gray-700 min-h-[56px] mb-3 transition-all duration-300">
          {busy && <div className="text-xs text-emerald-700 animate-pulse mb-1">â— {language === Language.HEBREW ? '×”××¢×¨×›×ª ×¨×¦×”...' : language === Language.ENGLISH ? 'Running...' : 'Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ...'}</div>}
          {status || (language === Language.HEBREW ? '××•×›×Ÿ ×œ×”×ª×—×œ×”.' : language === Language.ENGLISH ? 'Ready to start.' : 'Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğº Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ.')}
        </div>

        {started && (
          <div className="mb-3 rounded-xl border border-indigo-100 bg-indigo-50/40 p-3">
            <div className="text-xs font-black text-indigo-700 mb-2">
              {language === Language.HEBREW ? '×¤×™×“×‘×§ ×‘×–××Ÿ ×××ª (×‘××”×œ×š ×§×•×œ/×•×™×“××•)' : language === Language.ENGLISH ? 'Real-time feedback (during audio/video)' : 'ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ (Ğ°ÑƒĞ´Ğ¸Ğ¾/Ğ²Ğ¸Ğ´ĞµĞ¾)'}
            </div>
            <div className="text-xs text-gray-700 mb-1">
              {language === Language.HEBREW ? '×›×¨×’×¢ ×–×” × ×¢×™×?' : language === Language.ENGLISH ? 'Feels comfortable right now?' : 'Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ ĞºĞ¾Ğ¼Ñ„Ğ¾Ñ€Ñ‚Ğ½Ğ¾?'}
            </div>
            <div className="grid grid-cols-2 gap-2 mb-2">
              <button
                onClick={() => setLiveFeedback((p) => ({ ...p, comfortNow: true }))}
                className={'px-3 py-2 rounded-lg font-bold ' + (liveFeedback.comfortNow === true ? 'bg-emerald-600 text-white' : 'bg-emerald-100 text-emerald-800')}
              >
                {t.yes}
              </button>
              <button
                onClick={() => setLiveFeedback((p) => ({ ...p, comfortNow: false }))}
                className={'px-3 py-2 rounded-lg font-bold ' + (liveFeedback.comfortNow === false ? 'bg-rose-600 text-white' : 'bg-rose-100 text-rose-800')}
              >
                {t.no}
              </button>
            </div>
            <div className="text-xs text-gray-700 mb-1">
              {language === Language.HEBREW ? '×™×© ×”×¡×—×•×ª ×“×¢×ª ×‘×¨×§×¢?' : language === Language.ENGLISH ? 'Are there distractions now?' : 'Ğ•ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑĞµĞ¹Ñ‡Ğ°Ñ?'}
            </div>
            <div className="grid grid-cols-2 gap-2">
              <button
                onClick={() => setLiveFeedback((p) => ({ ...p, distractedNow: true }))}
                className={'px-3 py-2 rounded-lg font-bold ' + (liveFeedback.distractedNow === true ? 'bg-amber-600 text-white' : 'bg-amber-100 text-amber-800')}
              >
                {t.yes}
              </button>
              <button
                onClick={() => setLiveFeedback((p) => ({ ...p, distractedNow: false }))}
                className={'px-3 py-2 rounded-lg font-bold ' + (liveFeedback.distractedNow === false ? 'bg-indigo-600 text-white' : 'bg-indigo-100 text-indigo-800')}
              >
                {t.no}
              </button>
            </div>
          </div>
        )}

        <div className="mb-3 rounded-xl border border-emerald-100 bg-emerald-50/40 p-3">
          <div className="flex items-center justify-between gap-2">
            <div className="text-xs text-emerald-800 font-semibold">
              {language === Language.HEBREW ? '×•×™×“××• ××•×¤×¦×™×•× ×œ×™ ×œ×ª×™×¢×•×“ ×”×¡×©×Ÿ' : language === Language.ENGLISH ? 'Optional video for session recording' : 'ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ ÑĞµÑÑĞ¸Ğ¸'}
            </div>
            {!videoRecording ? (
              <button onClick={startVideoCapture} className="px-3 py-1 rounded-lg bg-emerald-600 text-white text-xs font-bold">{t.videoStart}</button>
            ) : (
              <button onClick={stopVideoCapture} className="px-3 py-1 rounded-lg bg-rose-600 text-white text-xs font-bold">{t.videoStop}</button>
            )}
          </div>
          <div className="text-xs text-gray-700 mt-2">
            Video: {videoPermission} {videoCapturedMs ? `| ${Math.round(videoCapturedMs / 1000)}s` : ''} {videoRecording ? '| REC' : ''}
          </div>
        </div>

        {moduleId === 'frequency' && stepIndex === 2 && (
          <div className="mb-3 rounded-xl border border-gray-200 p-3">
            <div className="text-sm font-semibold text-gray-700 mb-2">
              {language === Language.HEBREW ? '××™×–×” ×ª×“×¨ ×”×™×” ×”×›×™ × ×¢×™×?' : language === Language.ENGLISH ? 'Which tone felt most pleasant?' : 'ĞšĞ°ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ğ½ Ğ±Ñ‹Ğ» ÑĞ°Ğ¼Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½Ñ‹Ğ¼?'}
            </div>
            <div className="grid grid-cols-4 gap-2 mb-3">
              {FREQUENCY_SERIES.map((hz) => (
                <button
                  key={`liked-${hz}`}
                  onClick={() => setFrequencyFeedback((prev) => ({ ...prev, likedHz: hz }))}
                  className={`px-2 py-1 rounded-lg text-xs font-bold ${frequencyFeedback.likedHz === hz ? 'bg-emerald-600 text-white' : 'bg-emerald-100 text-emerald-800'}`}
                >
                  {hz}
                </button>
              ))}
            </div>

            <div className="text-sm font-semibold text-gray-700 mb-2">
              {language === Language.HEBREW ? '××™×–×” ×ª×“×¨ ×”×™×” ×¤×—×•×ª × ×¢×™×?' : language === Language.ENGLISH ? 'Which tone felt less pleasant?' : 'ĞšĞ°ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ğ½ Ğ±Ñ‹Ğ» Ğ¼ĞµĞ½ĞµĞµ Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½Ñ‹Ğ¼?'}
            </div>
            <div className="grid grid-cols-4 gap-2">
              {FREQUENCY_SERIES.map((hz) => (
                <button
                  key={`disliked-${hz}`}
                  onClick={() => setFrequencyFeedback((prev) => ({ ...prev, dislikedHz: hz }))}
                  className={`px-2 py-1 rounded-lg text-xs font-bold ${frequencyFeedback.dislikedHz === hz ? 'bg-rose-600 text-white' : 'bg-rose-100 text-rose-800'}`}
                >
                  {hz}
                </button>
              ))}
            </div>
          </div>
        )}

        {moduleId === 'speech' && stepIndex === 2 && (
          <div className="mb-3 rounded-xl border border-gray-200 p-3">
            <div className="text-sm font-semibold text-gray-700 mb-2">
              {language === Language.HEBREW ? '×©××œ×•×ª ×§×¦×¨×•×ª ×¢×œ ×”×¡×©×Ÿ' : language === Language.ENGLISH ? 'Short session questions' : 'ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ğ¾ ÑĞµÑÑĞ¸Ğ¸'}
            </div>

            <div className="text-xs font-semibold text-gray-700 mb-1">{language === Language.HEBREW ? '×©××¢×ª ××ª ×¢×¦××š ×‘×¨×•×¨?' : language === Language.ENGLISH ? 'Did you hear yourself clearly?' : 'Ğ’Ñ‹ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ ÑĞ»Ñ‹ÑˆĞ°Ğ»Ğ¸ ÑĞµĞ±Ñ?'}</div>
            <div className="grid grid-cols-2 gap-2 mb-2">
              <button onClick={() => setSpeechAnswers((p) => ({ ...p, heardClearly: true }))} className={`px-3 py-2 rounded-lg font-bold ${speechAnswers.heardClearly === true ? 'bg-emerald-600 text-white' : 'bg-emerald-100 text-emerald-800'}`}>{t.yes}</button>
              <button onClick={() => setSpeechAnswers((p) => ({ ...p, heardClearly: false }))} className={`px-3 py-2 rounded-lg font-bold ${speechAnswers.heardClearly === false ? 'bg-emerald-600 text-white' : 'bg-emerald-100 text-emerald-800'}`}>{t.no}</button>
            </div>

            <div className="text-xs font-semibold text-gray-700 mb-1">{language === Language.HEBREW ? '×”×™×• ×”×¡×—×•×ª ×“×¢×ª ×‘×–××Ÿ ×”×”×§×œ×˜×”?' : language === Language.ENGLISH ? 'Were there distractions during recording?' : 'Ğ‘Ñ‹Ğ»Ğ¸ Ğ¾Ñ‚Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸?'}</div>
            <div className="grid grid-cols-2 gap-2 mb-2">
              <button onClick={() => setSpeechAnswers((p) => ({ ...p, distracted: true }))} className={`px-3 py-2 rounded-lg font-bold ${speechAnswers.distracted === true ? 'bg-rose-600 text-white' : 'bg-rose-100 text-rose-800'}`}>{t.yes}</button>
              <button onClick={() => setSpeechAnswers((p) => ({ ...p, distracted: false }))} className={`px-3 py-2 rounded-lg font-bold ${speechAnswers.distracted === false ? 'bg-rose-600 text-white' : 'bg-rose-100 text-rose-800'}`}>{t.no}</button>
            </div>

            <div className="text-xs font-semibold text-gray-700 mb-1">{language === Language.HEBREW ? '×ª×¨×¦×” ×¡×‘×‘ ×—×•×–×¨?' : language === Language.ENGLISH ? 'Do you want a repeat round?' : 'ĞÑƒĞ¶ĞµĞ½ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€?'}</div>
            <div className="grid grid-cols-2 gap-2">
              <button onClick={() => setSpeechAnswers((p) => ({ ...p, wantsRepeat: true }))} className={`px-3 py-2 rounded-lg font-bold ${speechAnswers.wantsRepeat === true ? 'bg-indigo-600 text-white' : 'bg-indigo-100 text-indigo-800'}`}>{t.yes}</button>
              <button onClick={() => setSpeechAnswers((p) => ({ ...p, wantsRepeat: false }))} className={`px-3 py-2 rounded-lg font-bold ${speechAnswers.wantsRepeat === false ? 'bg-indigo-600 text-white' : 'bg-indigo-100 text-indigo-800'}`}>{t.no}</button>
            </div>
          </div>
        )}

        {moduleId === 'behavior' && (stepIndex === 0 || stepIndex === 1) && (
          <div className="mb-3 rounded-xl border border-gray-200 p-3">
            <div className="text-sm font-semibold text-gray-700 mb-2">
              {stepIndex === 0
                ? language === Language.HEBREW
                  ? '×”×× ×™×© ×¨×’×™×©×•×ª ×œ×¨×¢×©×™× ×—×–×§×™×?'
                  : language === Language.ENGLISH
                  ? 'Is there sensitivity to loud sounds?'
                  : 'Ğ•ÑÑ‚ÑŒ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğº Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¸Ğ¼ Ğ·Ğ²ÑƒĞºĞ°Ğ¼?'
                : language === Language.HEBREW
                ? '×”×× ×™×© ×§×•×©×™ ×‘×©×™× ×” ××• ×¨×™×›×•×–?'
                : language === Language.ENGLISH
                ? 'Any sleep or focus difficulty?'
                : 'Ğ•ÑÑ‚ÑŒ Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ¾ ÑĞ½Ğ¾Ğ¼ Ğ¸Ğ»Ğ¸ ĞºĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹?'}
            </div>
            <div className="grid grid-cols-2 gap-2">
              <button
                onClick={() => setBehaviorAnswers((prev) => ({ ...prev, [stepIndex === 0 ? 'q1' : 'q2']: true }))}
                className={`px-3 py-2 rounded-lg font-bold ${(stepIndex === 0 ? behaviorAnswers.q1 : behaviorAnswers.q2) === true ? 'bg-emerald-600 text-white' : 'bg-emerald-100 text-emerald-800'}`}
              >
                {t.yes}
              </button>
              <button
                onClick={() => setBehaviorAnswers((prev) => ({ ...prev, [stepIndex === 0 ? 'q1' : 'q2']: false }))}
                className={`px-3 py-2 rounded-lg font-bold ${(stepIndex === 0 ? behaviorAnswers.q1 : behaviorAnswers.q2) === false ? 'bg-emerald-600 text-white' : 'bg-emerald-100 text-emerald-800'}`}
              >
                {t.no}
              </button>
            </div>
          </div>
        )}

        <div className="grid grid-cols-2 gap-2 mb-3">
          <button onClick={onBack} disabled={busy} className="px-4 py-3 rounded-xl bg-gray-100 hover:bg-gray-200 disabled:opacity-60 text-gray-700 font-bold">
            {t.back}
          </button>

          {!started ? (
            <button
              onClick={async () => {
                setStarted(true);
                setStatus(t.startedLog);
                pushLog(t.startedLog);
                await runCurrentStep();
              }}
              disabled={busy}
              className="px-4 py-3 rounded-xl bg-emerald-600 hover:bg-emerald-700 disabled:opacity-60 text-white font-bold"
            >
              {busy ? 'â€¦' : t.start}
            </button>
          ) : (
            <button onClick={runCurrentStep} disabled={busy} className="px-4 py-3 rounded-xl bg-emerald-600 hover:bg-emerald-700 disabled:opacity-60 text-white font-bold">
              {busy ? 'â€¦' : isLastStep ? t.complete : t.continue}
            </button>
          )}
        </div>

        <div className="mb-3 rounded-xl border border-emerald-100 bg-emerald-50/40 p-3">
          <div className="text-xs font-black text-emerald-700 mb-2">{language === Language.HEBREW ? '× ×ª×•× ×™ ××‘×—×•×Ÿ' : language === Language.ENGLISH ? 'Diagnostic Data' : 'Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ'}</div>
          <div className="text-xs text-gray-700 space-y-1">
            <div>Mic: {micPermission}</div>
            <div>Ambient: {ambientDb !== null ? `${ambientDb} dB` : '-'}</div>
            <div>Last tone: {lastToneHz !== null ? `${lastToneHz} Hz` : '-'}</div>
            <div>Recording: {recordingMs !== null ? `${Math.round(recordingMs / 1000)} s` : '-'}</div>
            <div>Video: {videoPermission}{videoCapturedMs !== null ? `, ${Math.round(videoCapturedMs / 1000)} s` : ''}</div>
            <div>Distraction: focusLost={focusLostCount}, hidden={hiddenCount}, motionEvents={motionEvents}, motionAvg={motionScoreAvg ?? '-'}</div>
            {moduleId === 'frequency' && <div>Feedback: pleasant={frequencyFeedback.likedHz ?? '-'}Hz, less-pleasant={frequencyFeedback.dislikedHz ?? '-'}Hz</div>}
            <div>Live: comfort={typeof liveFeedback.comfortNow === 'boolean' ? (liveFeedback.comfortNow ? 'yes' : 'no') : '-'}, distractedNow={typeof liveFeedback.distractedNow === 'boolean' ? (liveFeedback.distractedNow ? 'yes' : 'no') : '-'}</div>
            {moduleId === 'speech' && <div>Speech Q: clear={typeof speechAnswers.heardClearly === 'boolean' ? (speechAnswers.heardClearly ? 'yes' : 'no') : '-'}, distracted={typeof speechAnswers.distracted === 'boolean' ? (speechAnswers.distracted ? 'yes' : 'no') : '-'}, repeat={typeof speechAnswers.wantsRepeat === 'boolean' ? (speechAnswers.wantsRepeat ? 'yes' : 'no') : '-'}</div>}
            {moduleId === 'behavior' && <div>Behavior: q1={typeof behaviorAnswers.q1 === 'boolean' ? (behaviorAnswers.q1 ? 'yes' : 'no') : '-'}, q2={typeof behaviorAnswers.q2 === 'boolean' ? (behaviorAnswers.q2 ? 'yes' : 'no') : '-'}</div>}
          </div>
        </div>

        <div className="rounded-xl border border-gray-200 p-3 bg-white">
          <div className="text-xs font-black text-gray-700 mb-2">{language === Language.HEBREW ? '×œ×•×’ ××‘×—×•×Ÿ' : language === Language.ENGLISH ? 'Diagnostic Log' : 'Ğ›Ğ¾Ğ³ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸'}</div>
          {eventLog.length === 0 ? (
            <div className="text-xs text-gray-500">{language === Language.HEBREW ? '×¢×“×™×™×Ÿ ××™×Ÿ ××™×¨×•×¢×™×.' : language === Language.ENGLISH ? 'No events yet.' : 'ĞŸĞ¾ĞºĞ° Ğ½ĞµÑ‚ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹.'}</div>
          ) : (
            <div className="max-h-28 overflow-y-auto space-y-1">
              {eventLog.map((line, idx) => (
                <div key={`${idx}-${line.slice(0, 10)}`} className="text-xs text-gray-700">â€¢ {line}</div>
              ))}
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default DiagnosticModuleRunner;
